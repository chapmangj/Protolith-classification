{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chapmangj/Protolith-classification/blob/main/notebooks/train_protolith_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrzfsEO0oy_6"
      },
      "source": [
        "\n",
        "# Protolith classification model training script.\n",
        "\n",
        "Model uses major element geochemistry and a balanced random forrest algorithm to discriminate sedimentary from ignous protoliths.\n",
        "\n",
        "Scripts to create and train final model pipeline on complete dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "c1dpjPhaoy_8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "import joblib\n",
        "\n",
        "from datetime import datetime\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNZ4nQUUpDRb",
        "outputId": "c14183db-1305-48ba-8158-a9f3e3091942"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import imblearn\n",
        "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"imbalanced-learn version: {imblearn.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYY-dajhtqLo",
        "outputId": "fb4905c0-501f-4ccd-bb73-2fecf67f3e23"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn version: 1.6.1\n",
            "imbalanced-learn version: 0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuGCVMGooy_8"
      },
      "source": [
        "## Enter Paths to training dataset and model output location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "i-96-cAAoy_9"
      },
      "outputs": [],
      "source": [
        "#Path to complete training dataset\n",
        "in_path = r'/content/classifier_data_2019-02-26_ilr_training.csv'\n",
        "\n",
        "#Path to location to save model\n",
        "out_path = r'/content/drive/MyDrive/protolith'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1Oh2QtPoy_9"
      },
      "source": [
        "## Training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "TGTkn62joy_9"
      },
      "outputs": [],
      "source": [
        "def load_training_data(path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Function to load the protolith model training data from file. Data is already in Atchison simplex form.\n",
        "    Parameters:\n",
        "        path: path to training data as string\n",
        "    returns:\n",
        "        training dataset X_train, y_train\n",
        "    \"\"\"\n",
        "    p = Path(path)\n",
        "    try:\n",
        "        if p.exists and p.suffix == '.csv':\n",
        "            df = pd.read_csv(p, encoding='latin-1') #training set\n",
        "            print(\"Columns in the loaded DataFrame:\", df.columns.tolist()) # Print column names\n",
        "        else:\n",
        "             raise FileNotFoundError(\"File does not exist or is not a CSV.\")\n",
        "    except Exception as e:\n",
        "        print(f'could not read training data file: {e}')\n",
        "        raise e # Re-raise the exception after printing\n",
        "\n",
        "    #create raw X training set and binary labeled y array\n",
        "    X_train, y_train = df[['sio2','tio2','al2o3','feo_tot','mgo','cao','na2o','k2o','p2o5']], df[['rock_group']].replace(['igneous','sedimentary'],[0,1])\n",
        "\n",
        "    return X_train, y_train\n",
        "\n",
        "def train_model(X: pd.DataFrame, y: pd.Series) -> sklearn.pipeline.Pipeline:\n",
        "    \"\"\"\n",
        "    Function to train the protolith classification model.\n",
        "    \"\"\"\n",
        "    cv = StratifiedKFold(n_splits=5, random_state=101, shuffle=True)\n",
        "\n",
        "    clsf_pipe = Pipeline([\n",
        "        ('sc', StandardScaler()),\n",
        "        ('classifier', CalibratedClassifierCV(\n",
        "            estimator=BalancedRandomForestClassifier(  # Changed from base_estimator to estimator\n",
        "                n_estimators=50,\n",
        "                max_depth=15,\n",
        "                min_samples_leaf=1,\n",
        "                min_samples_split=2,\n",
        "                max_features='sqrt',\n",
        "                sampling_strategy='not minority',\n",
        "                n_jobs=-1,\n",
        "                random_state=101\n",
        "            ),\n",
        "            method='sigmoid',\n",
        "            cv=cv\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    model_pipe = clsf_pipe.fit(X, y)\n",
        "    return model_pipe\n",
        "\n",
        "def save_model(model, name: str, out_path: str):\n",
        "    \"\"\"\n",
        "    Function to save trained protolith classification model.\n",
        "    Paramaters:\n",
        "        model: trained sklearn model pipe\n",
        "        name: str. File name (will be appended with date and time)\n",
        "        out_path: str. path to export file to\n",
        "    returns\n",
        "        joblib file\n",
        "    \"\"\"\n",
        "    now = datetime.now().strftime(\"%Y-%M-%d-%H-%M\")\n",
        "    file_name = f'{name}_{now}.joblib'\n",
        "    p = Path(out_path) / file_name\n",
        "    joblib.dump(model, p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtBNU-kmoy_9"
      },
      "source": [
        "## Script to load data, train model and output saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIXXaaocoy_9",
        "outputId": "8a010b1f-b96f-46cd-9bd4-896f8ee1a3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-350038775.py:13: DtypeWarning: Columns (3,4,5,6,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(p, encoding='latin-1') #training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the loaded DataFrame: ['rock_group', 'rock_type', 'sample_id', 'author', 'title', 'journal', 'year', 'doi', 'bibtex', 'sio2', 'tio2', 'al2o3', 'feo_tot', 'mgo', 'cao', 'na2o', 'k2o', 'p2o5', 'index', 'coord_1', 'coord_2', 'coord_3', 'coord_4', 'coord_5', 'coord_6', 'coord_7', 'coord_8']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-350038775.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  X_train, y_train = df[['sio2','tio2','al2o3','feo_tot','mgo','cao','na2o','k2o','p2o5']], df[['rock_group']].replace(['igneous','sedimentary'],[0,1])\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = load_training_data(in_path)\n",
        "\n",
        "model = train_model(X_train, y_train)\n",
        "\n",
        "save_model(model, 'Model50_15_full', out_path)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python361064bitpycaretconda04d964cf706c4fb9995a657b6f62f611",
      "display_name": "Python 3.6.10 64-bit ('pycaret': conda)"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
